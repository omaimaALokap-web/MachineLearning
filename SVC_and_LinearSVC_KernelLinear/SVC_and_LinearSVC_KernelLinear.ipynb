{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f7iJahKqlvM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "0gCftWaIrAAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMNP7ETsbyk",
        "outputId": "a7f1765e-b3f4-44f6-f171-13b074214153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 32','id'], inplace = True, axis = 1)"
      ],
      "metadata": {
        "id": "CT5GuPGxsdYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})"
      ],
      "metadata": {
        "id": "IU5MDzSesnw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Scaling_overSampling(x,y, Scaling_fun, overs = False):\n",
        "  Scaling_fun.fit(x)\n",
        "  scaled_x = Scaling_fun.transform(x)\n",
        "  ovr = RandomOverSampler()\n",
        "  if overs:\n",
        "    X, Y = ovr.fit_resample(scaled_x,y)\n",
        "  else:\n",
        "    X, Y = scaled_x, y\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "ZdhEFPoMsyOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = df.drop('diagnosis', axis = 1)\n",
        "Y_t = df['diagnosis']"
      ],
      "metadata": {
        "id": "kj4Ipd4-uRJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = Scaling_overSampling(X_t, Y_t, StandardScaler(), True)"
      ],
      "metadata": {
        "id": "lM9RugpXu5V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tarin, X_test, Y_tarin, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "lRKT2mO1wm76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel = Linear"
      ],
      "metadata": {
        "id": "KTruxE7tv4Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_svc  = SVC(kernel='linear',C=10,  random_state=42)\n",
        "crose  = cross_val_score(l_svc, X_tarin, Y_tarin, cv = 5)\n",
        "print (\"the traing accuracy\",crose.mean())\n",
        "train_x =l_svc.fit(X_tarin, Y_tarin)\n",
        "print (\"the testing accuracy\",train_x.score(X_test,Y_test))\n",
        "y_pred = l_svc.predict(X_test)\n",
        "print(\"accuracy_score\",accuracy_score(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_y6E5EMvM3u",
        "outputId": "72586117-96fa-47b1-9402-4011d280ad36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the traing accuracy 0.9649427917620137\n",
            "the testing accuracy 0.9790209790209791\n",
            "accuracy_score 0.9790209790209791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVC"
      ],
      "metadata": {
        "id": "GH3m6Jk_x8rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_svc  = LinearSVC(C=10,random_state=42, dual=False)\n",
        "crose  = cross_val_score(l_svc, X_tarin, Y_tarin, cv = 5)\n",
        "print (\"the traing accuracy\",crose.mean())\n",
        "train_x =l_svc.fit(X_tarin, Y_tarin)\n",
        "print (\"the testing accuracy\",train_x.score(X_test,Y_test))\n",
        "y_pred = l_svc.predict(X_test)\n",
        "print(\"accuracy_score\",accuracy_score(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkbp5qhHwLRi",
        "outputId": "0ae4afc8-3dd3-4c16-a46e-d1e224d8a359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the traing accuracy 0.9632189168573607\n",
            "the testing accuracy 0.986013986013986\n",
            "accuracy_score 0.986013986013986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGDClassifier\n",
        "It is better use it for Linear data and with large dataset. However, Desicion tree and svm better"
      ],
      "metadata": {
        "id": "-YFoZsYZ-Wgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss{‘hinge’, ‘log_loss’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’, ‘squared_error’, ‘huber’, ‘epsilon_insensitive’, ‘squared_epsilon_insensitive’}, default=’hinge’\n",
        "The loss function to be used.\n",
        "\n",
        "‘hinge’ gives a linear SVM.\n",
        "\n",
        "‘log_loss’ gives logistic regression, a probabilistic classifier.\n",
        "\n",
        "‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates.\n",
        "\n",
        "‘squared_hinge’ is like hinge but is quadratically penalized.\n",
        "\n",
        "‘perceptron’ is the linear loss used by the perceptron algorithm.\n",
        "\n",
        "The other losses, ‘squared_error’, ‘huber’, ‘epsilon_insensitive’ and ‘squared_epsilon_insensitive’ are designed for regression but can be useful in classification as well; see SGDRegressor for a description.\n",
        "\n",
        "More details about the losses formulas can be found in the User Guide.\n",
        "\n",
        "penalty{‘l2’, ‘l1’, ‘elasticnet’, None}, default=’l2’\n",
        "The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ might bring sparsity to the model (feature selection) not achievable with ‘l2’. No penalty is added when set to None.\n",
        "\n",
        "alphafloat, default=0.0001\n",
        "Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when learning_rate is set to ‘optimal’. Values must be in the range [0.0, inf)."
      ],
      "metadata": {
        "id": "kfxxCDgEBtOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "XkP-7Nf5yP7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SGDClassifier(loss='log_loss', alpha=0.01, random_state=42)\n",
        "crose  = cross_val_score(clf, X_tarin, Y_tarin, cv = 5)\n",
        "print (\"the traing accuracy\",crose.mean())\n",
        "train_x =clf.fit(X_tarin, Y_tarin)\n",
        "print (\"the testing accuracy\",train_x.score(X_test,Y_test))\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"accuracy_score\",accuracy_score(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q6EoZnZ-p8r",
        "outputId": "49b845bd-54eb-4e7c-ec48-be4c7df5d34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the traing accuracy 0.9772387490465293\n",
            "the testing accuracy 0.965034965034965\n",
            "accuracy_score 0.965034965034965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gVfDsCJ0-scC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}