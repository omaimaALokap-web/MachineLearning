{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NwazKyuAnPq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6N7Mco9EApjK",
        "outputId": "42bf245e-a76c-469a-cbd6-9344265f3796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 32','id'], inplace = True, axis = 1 )"
      ],
      "metadata": {
        "id": "iPlzXZ4qBfkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})"
      ],
      "metadata": {
        "id": "OsYRELquBqy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Traing_score ={}\n",
        "Testing_score = {}\n",
        "Model_accuracy = {}\n"
      ],
      "metadata": {
        "id": "ABHyMvTyDuwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling and OverSampling"
      ],
      "metadata": {
        "id": "-pqXsh6pBuk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling(X,Y, scale,over_sampling = False):\n",
        "  scale.fit(X)\n",
        "  scaled_data = scale.transform(X)\n",
        "  osr = RandomOverSampler()\n",
        "  if over_sampling:\n",
        "    x_scaled, y_osr = osr.fit_resample(scaled_data, Y)\n",
        "  else:\n",
        "    x_scaled = scaled_data\n",
        "    y_osr = Y\n",
        "  return x_scaled, y_osr"
      ],
      "metadata": {
        "id": "-S7EY1A7Brdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid"
      ],
      "metadata": {
        "id": "-le950xkCHRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = {\n",
        "    'C':[0.1,1,10,100],\n",
        "    'gamma':[1,0.1,0.01,0.001],\n",
        "    'kernel':['linear','poly','sigmoid','rbf','laplacian'],\n",
        "    'degree':[1,2,3,4,5]\n",
        "}"
      ],
      "metadata": {
        "id": "IhcDvaVdB6en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('diagnosis', axis = 1)\n",
        "Y = df['diagnosis']"
      ],
      "metadata": {
        "id": "fpRf6PsiEg-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Scaling"
      ],
      "metadata": {
        "id": "9o4s-6PzFVIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "svc_m = SVC(random_state=101)\n",
        "cross_val = cross_val_score(svc_m, X_train, y_train, cv = 5)\n",
        "Traing_score['Default_valuse'] = np.mean(cross_val)\n",
        "print(\"The traing accuracy\", Traing_score['Default_valuse'])\n",
        "svc_m.fit(X_train, y_train)\n",
        "Testing_score['Default_values'] = svc_m.fit(X_train, y_train).score(X_test, y_test)\n",
        "print('The test accuracy',Testing_score['Default_values'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W3aq7L_CJvs",
        "outputId": "e14919b7-cb84-4280-f8c3-867813cda4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traing accuracy 0.8943354430379747\n",
            "The test accuracy 0.935672514619883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Scaling"
      ],
      "metadata": {
        "id": "EbqI7caPFdV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, False)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  svc_m = SVC(random_state=101)\n",
        "  cross_val = cross_val_score(svc_m, X_train, y_train, cv = 5)\n",
        "  Traing_score[f'Default_valuse-{i}'] = np.mean(cross_val)\n",
        "  print(f\"The traing accuracy-{i}\", Traing_score[f'Default_valuse-{i}'])\n",
        "  svc_m.fit(X_train, y_train)\n",
        "  Testing_score[f'Default_valuse-{i}'] = svc_m.fit(X_train, y_train).score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}',Testing_score[f'Default_valuse-{i}'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbc8f4f-c40a-4c7f-88bf-55151b72df17",
        "id": "Ahr_IsJCFpbr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traing accuracy-StandardScaler() 0.9672784810126581\n",
            "The test accuracy-StandardScaler() 0.9707602339181286\n",
            "The traing accuracy-MinMaxScaler() 0.9723734177215189\n",
            "The test accuracy-MinMaxScaler() 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling and Oversampling"
      ],
      "metadata": {
        "id": "QKWbu3dUHR2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, True)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  svc_m = SVC(random_state=101)\n",
        "  cross_val = cross_val_score(svc_m, X_train, y_train, cv = 5)\n",
        "  Traing_score[f'Default_valuse-{i}-OverSamp'] = np.mean(cross_val)\n",
        "  print(f\"The traing accuracy-{i}-OverSamp\", Traing_score[f'Default_valuse-{i}-OverSamp'])\n",
        "  svc_m.fit(X_train, y_train)\n",
        "  Testing_score[f'Default_valuse-{i}-OverSamp'] = svc_m.fit(X_train, y_train).score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}-Oversamp',Testing_score[f'Default_valuse-{i}-OverSamp'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gargpkCEGnDx",
        "outputId": "94080956-d6cf-4805-a739-302a4df7ba27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traing accuracy-StandardScaler()-OverSamp 0.9759595959595959\n",
            "The test accuracy-StandardScaler()-Oversamp 0.9627906976744186\n",
            "The traing accuracy-MinMaxScaler()-OverSamp 0.9779595959595959\n",
            "The test accuracy-MinMaxScaler()-Oversamp 0.9767441860465116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid"
      ],
      "metadata": {
        "id": "nKoT9PzjNO-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "svc_m = SVC(random_state = 101)\n",
        "svc_grid = GridSearchCV(svc_m , grid , cv = 5)\n",
        "svc_grid.fit(X_train, y_train)\n",
        "print(f\"the best parameters :{svc_grid.best_params_}\")\n",
        "Traing_score['Grid_valuse'] = svc_grid.best_score_\n",
        "print(\"The traing accuracy\", Traing_score['Grid_valuse'])\n",
        "Testing_score['Grid_valuse'] = svc_grid.score(X_test, y_test)\n",
        "print('The test accuracy',Testing_score['Grid_valuse'])"
      ],
      "metadata": {
        "id": "8v-ILbk1NRjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid with Sampling"
      ],
      "metadata": {
        "id": "xKqKz_EhIimA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, False)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  svc_m = SVC(random_state = 101)\n",
        "  svc_grid = GridSearchCV(svc_m , grid , cv = 5)\n",
        "  svc_grid.fit(X_train, y_train)\n",
        "  print(f\"the best parameters :{svc_grid.best_params_}\")\n",
        "  Traing_score[f'Grid_valuse-{i}'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}\", Traing_score[f'Grid_valuse-{i}'])\n",
        "  Testing_score[f'Grid_valuse-{i}'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}',Testing_score[f'Grid_valuse-{i}'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6Exa7wH28H",
        "outputId": "8393b6b3-5d85-4290-e4b3-2da35ea300d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the best parameters :{'C': 1, 'degree': 1, 'gamma': 1, 'kernel': 'linear'}\n",
            "The traing accuracy-StandardScaler() 0.9748101265822784\n",
            "The test accuracy-StandardScaler() 0.9766081871345029\n",
            "the best parameters :{'C': 1, 'degree': 2, 'gamma': 1, 'kernel': 'poly'}\n",
            "The traing accuracy-MinMaxScaler() 0.977373417721519\n",
            "The test accuracy-MinMaxScaler() 0.9883040935672515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid with scalling and oversampling"
      ],
      "metadata": {
        "id": "M0d3kFYFNAfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, True)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  svc_m = SVC(random_state = 101)\n",
        "  svc_grid = GridSearchCV(svc_m , grid , cv = 5)\n",
        "  svc_grid.fit(X_train, y_train)\n",
        "  print(f\"the best parameters :{svc_grid.best_params_}\")\n",
        "  Traing_score[f'Grid_valuse-{i}-OVS'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}-OVS\", Traing_score[f'Grid_valuse-{i}-OVS'])\n",
        "  Testing_score[f'Grid_valuse-{i}-OVS'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}-OVS',Testing_score[f'Grid_valuse-{i}-OVS'])"
      ],
      "metadata": {
        "id": "Ot-QheQZMm4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kv6msWXdNKx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(Traing_score, index=['Traing_score'])\n",
        "df2 = pd.DataFrame(Testing_score, index=['Testing_score'])\n",
        "\n",
        "Scores = pd.concat([df1, df2], axis=1)\n",
        "Scores"
      ],
      "metadata": {
        "id": "ZilTejhMOiIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linearsvc"
      ],
      "metadata": {
        "id": "v2wZTAxKRppX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "Traing_score[f'clf_valuse-{i}'] = svc_grid.best_score_\n",
        "print(f\"The traing accuracy-{i}\", Traing_score[f'clf_valuse-{i}'])\n",
        "Testing_score[f'clf_valuse-{i}'] = svc_grid.score(X_test, y_test)\n",
        "print(f'The test accuracy-{i}',Testing_score[f'clf_valuse-{i}'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v9McNRQZQLBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LinearSVC with scaling"
      ],
      "metadata": {
        "id": "m5-tFi8LRIx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, False)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  clf = LinearSVC()\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  Traing_score[f'clf_valuse-{i}'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}\", Traing_score[f'clf_valuse-{i}'])\n",
        "  Testing_score[f'clf_valuse-{i}'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}',Testing_score[f'clf_valuse-{i}'])"
      ],
      "metadata": {
        "id": "7vhkDh-gRYh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  LinearSVC with scaling and oversampling"
      ],
      "metadata": {
        "id": "Yyo1d74ZR15P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, True)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  clf = LinearSVC()\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  Traing_score[f'clf_valuse-{i}-ovs'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}-ovs\", Traing_score[f'clf_valuse-{i}-ovs'])\n",
        "  Testing_score[f'clf_valuse-{i}-ovs'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}-ovs',Testing_score[f'clf_valuse-{i}-ovs'])"
      ],
      "metadata": {
        "id": "UBUXGbagR6bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGDClassifier\n"
      ],
      "metadata": {
        "id": "4HsmTzVfSPH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "clf = SGDClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "Traing_score[f'clf_valuse-{i}'] = svc_grid.best_score_\n",
        "print(f\"The traing accuracy-{i}\", Traing_score[f'clf_valuse-{i}'])\n",
        "Testing_score[f'clf_valuse-{i}'] = svc_grid.score(X_test, y_test)\n",
        "print(f'The test accuracy-{i}',Testing_score[f'clf_valuse-{i}'])"
      ],
      "metadata": {
        "id": "l1PnnaikSRid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6JZUCGtSjVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, False)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  clf = clf = SGDClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  Traing_score[f'clf_valuse-{i}'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}\", Traing_score[f'clf_valuse-{i}'])\n",
        "  Testing_score[f'clf_valuse-{i}'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}',Testing_score[f'clf_valuse-{i}'])"
      ],
      "metadata": {
        "id": "UaiQM75LSjWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [StandardScaler(), MinMaxScaler()]:\n",
        "  X_scaled, Y_scaled = scaling(X,Y, i, True)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)\n",
        "  clf = clf = SGDClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  Traing_score[f'clf_valuse-{i}-ovs'] = svc_grid.best_score_\n",
        "  print(f\"The traing accuracy-{i}-ovs\", Traing_score[f'clf_valuse-{i}-ovs'])\n",
        "  Testing_score[f'clf_valuse-{i}-ovs'] = svc_grid.score(X_test, y_test)\n",
        "  print(f'The test accuracy-{i}-ovs',Testing_score[f'clf_valuse-{i}-ovs'])"
      ],
      "metadata": {
        "id": "VG1enP8HSow7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1UE6hPTITAw7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vsfj2dO6TCgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jT0BFHilTCh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with different hyperparameters\n",
        "clf = SGDClassifier(alpha=0.001, penalty='l1', learning_rate='adaptive')"
      ],
      "metadata": {
        "id": "ptGyULQQTCjS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}